


Learning result for safety specification:

P<=0.1[true U<=64 'unsafe']

>>>>>>>>Apprenticeship Learning learnt policy
PRISM model checking result: 0.857011

>>>>>>>>Safety-Aware Apprenticeship Learning learnt policy
PRISM model checking result: 0.000000
Experiment: mountaincar

>>>>>>>>Apprenticeship Learning learns a policy  which is an optimal policy of reward function as in the figure.
Given safety spec:
P=? [U<= 200 ((position < -0.9 && velocity < -0.03)||(position > 0.3 && velocity > 0.03))]

PRISM model checking the probability of reaching the unsafe states: 0.519563
Unsafe ratio: 0.720000Average step length: 65.000000