


Learning result for safety specification:

P<=0.35 [U<= 66 ((position < -0.9 && velocity < -0.03 )||(position > 0.3 && velocity > 0.03))]

>>>>>>>>Apprenticeship Learning learnt policy
PRISM model checking result: 0.519563

>>>>>>>>Safety-Aware Apprenticeship Learning learnt policy
PRISM model checking result: 0.296587
Unsafe ratio: 0.545000Average step length: 58.000000Experiment: mountaincar

>>>>>>>>Apprenticeship Learning learns a policy  which is an optimal policy of reward function as in the figure.
Given safety spec:
P=? [U<= 200 ((position < -0.9 && velocity < -0.03)||(position > 0.3 && velocity > 0.03))]

PRISM model checking the probability of reaching the unsafe states: 0.519563
